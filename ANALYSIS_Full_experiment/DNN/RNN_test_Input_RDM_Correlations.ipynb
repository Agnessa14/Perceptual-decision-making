{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the correlations for each layer and create input RDMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the function to create filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileName(n_samples, name):\n",
    "    return name \\\n",
    "        + \"_{}_\".format(n_samples) \\\n",
    "        + \"_{}_\".format(model_name) \\\n",
    "        + \"_{}\".format(layer_name)   \\\n",
    "        + \".npy\"       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the model and layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/mnt/raid/ni/agnessa/rcnn-sat'\n",
    "NR_OF_SAMPLES = 60\n",
    "\n",
    "num_layers = 7\n",
    "num_timepoints = 8\n",
    "layer_names = []\n",
    "for layer_idx in range(num_layers):\n",
    "    for timepoint in range(num_timepoints):       \n",
    "        layer_time = 'ReLU_Layer_{}_Time_{}'.format(layer_idx,timepoint)\n",
    "        layer_names.append(layer_time)\n",
    "\n",
    "model_name = '/model_02.11_2/'\n",
    "path_dnn = root_path+model_name\n",
    "\n",
    "# layer_name = layer_names[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my version\n",
    "def correlationd_matrix(batch_size): #(list_of_activations, n) ,array_activations\n",
    "    file_name = os.path.join(path_dnn+'normalized_nopca/activations/','{}_activations.npy'.format(layer_name)) \n",
    "#     act = np.load(file_name,mmap_mode='r') #mmap is used to access a part of the file \n",
    "    act_all = np.load(file_name,mmap_mode='r')\n",
    "    act = act_all[-NR_OF_SAMPLES:]\n",
    "    print(np.argwhere(np.isnan(act)))\n",
    "    correlationd = np.zeros((NR_OF_SAMPLES,NR_OF_SAMPLES))\n",
    "    correlationd[:] = np.nan\n",
    "    num_batches = int(NR_OF_SAMPLES / batch_size)\n",
    "    total = sum(x+1 for x in range(num_batches)) #num comparisons to do\n",
    "    index = 0\n",
    "   \n",
    "    for i in range(num_batches): \n",
    "        start_1 = batch_size*i\n",
    "        end_1 = batch_size*(i+1)\n",
    "        list_of_activations_1 = act[start_1:end_1,:]\n",
    "\n",
    "        for j in range(i,num_batches): \n",
    "            index += 1\n",
    "#             print(\"New Iteration: i = {0}, j = {1}; {2}/{3}\".format(i,j,index,total))\n",
    "            start_2 = batch_size*(j)\n",
    "            end_2 = batch_size*(j+1)\n",
    "            list_of_activations_2 = act[start_2:end_2,:]\n",
    "            corr_activations = 1-np.corrcoef(list_of_activations_1,list_of_activations_2) \n",
    "\n",
    "            for x in range(corr_activations.shape[0]):\n",
    "                for y in range(corr_activations.shape[1]):\n",
    "                    if x < batch_size:\n",
    "                        start_x = start_1\n",
    "                    else: \n",
    "                        start_x = start_2-batch_size\n",
    "                    if y < batch_size:\n",
    "                        start_y = start_1\n",
    "                    else:\n",
    "                        start_y = start_2-batch_size                       \n",
    "                    correlationd[x+start_x,y+start_y] = correlationd[y+start_y,x+start_x] = corr_activations[x,y]\n",
    "\n",
    "    return(correlationd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name in layer_names:\n",
    "    # layer_name = layer_names[0]\n",
    "    print('Calculating the correlations for model: ',model_name,'and layer: ',layer_name)\n",
    "    corr_matrix = correlationd_matrix(10) \n",
    "    path = os.path.join(path_dnn + 'normalized_nopca/Input_RDM/', '{}_Input_RDM.npy'.format(layer_name))\n",
    "    print(\"Save Input RDM -> {}\".format(path))\n",
    "    np.save(path, np.array(corr_matrix)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(17,13))\n",
    "ax = seaborn.heatmap(corr_matrix, cmap='rainbow', vmin=0.0, vmax=2.0)\n",
    "# path_fig = os.path.join(ROOT_PATH + 'Input_RDM_plots', getFileName(NR_OF_SAMPLES,\"Input_RDM_\") + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 7\n",
    "num_timepoints = 8\n",
    "for layer in range(num_layers):\n",
    "    directory = '/mnt/raid/ni/agnessa/rcnn-sat/model_02.11_2/normalized_nopca/'\n",
    "    filename = 'ReLU_Layer_{}_Time_7_Input_RDM'.format(layer)\n",
    "    mat = np.load(os.path.join(directory+'Input_RDM/','{}.npy'.format(filename)))\n",
    "   \n",
    "    fig = plt.figure(figsize=(17,13))\n",
    "    ax = seaborn.heatmap(mat, cmap='rainbow', vmin=0.0, vmax=1.0)\n",
    "    \n",
    "    fig.savefig(os.path.join(directory+'Input_RDM_plots/','{}.png'.format(filename)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case the load function does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #If the load function gives an error, do this\n",
    "# np_load_old = np.load # modify the default parameters of np.load\n",
    "# np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "# activations_shape = np.load(path)\n",
    "# np.load = np_load_old"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
